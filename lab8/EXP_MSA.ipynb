{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ecc530-9808-451a-b6f7-503f21ecb648",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28370de4-463b-4312-9c38-f87c0bf5c6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MOSIDataset(Dataset):\n",
    "    def __init__(self, data_path, split='train'):\n",
    "        # Load the data from the pickle file\n",
    "        with open(data_path, 'rb') as f:\n",
    "            data = pickle.load(f)\n",
    "        \n",
    "        # Select the appropriate split\n",
    "        self.vision = data[split]['vision']\n",
    "        self.text = data[split]['text']\n",
    "        self.audio = data[split]['audio']\n",
    "        self.labels = data[split]['labels']\n",
    "        self.ids = data[split]['id']\n",
    "\n",
    "        # audio数据中存在坏点需要处理：\n",
    "        self.audio[self.audio == float('inf')] = 0.0\n",
    "        self.audio[self.audio == float('-inf')] = 0.0\n",
    "\n",
    "    def __len__(self):\n",
    "        # TODO: 返回数据集长度\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Extract the features and label for the given index\n",
    "        vision = torch.tensor(self.vision[idx], dtype=torch.float32)\n",
    "        text = torch.tensor(self.text[idx], dtype=torch.float32)\n",
    "        audio = torch.tensor(self.audio[idx], dtype=torch.float32)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32).squeeze()\n",
    "\n",
    "        return vision, text, audio, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812a4a98-63c0-45b3-bd91-d0a6ad3e1411",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultimodalSentimentAnalysisModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MultimodalSentimentAnalysisModel, self).__init__()\n",
    " \n",
    "        self.vision_norm = nn.LayerNorm(35)\n",
    "        self.text_norm = nn.LayerNorm(300)\n",
    "        self.audio_norm = nn.LayerNorm(74)\n",
    "        \n",
    "        self.vision_fc = nn.Linear(35, 128)\n",
    "        self.text_fc = nn.Linear(300, 128)\n",
    "        self.audio_fc = nn.Linear(74, 128)\n",
    "        \n",
    "        # 定义vision_lstm, text_lstm 和 audio_lstm和融合层mm_lstm. 要求hidden_size=128, num_layers=1, dropout=0.1, batch_first=True\n",
    "        # TODO: self.vision_lstm\n",
    "        # TODO: self.text_lstm\n",
    "        # TODO: self.audio_lstm\n",
    "        # TODO: self.mm_lstm\n",
    "        \n",
    "        # Define a fully connected layer for fusion\n",
    "        self.fc = nn.Linear(128, 1)\n",
    "        \n",
    "    def forward(self, vision, text, audio):\n",
    "\n",
    "        # apply layernorm \n",
    "        # TODO\n",
    "        # TODO\n",
    "        # TODO\n",
    "        \n",
    "        # Process each modality\n",
    "        vision = F.relu(self.vision_fc(vision))\n",
    "        text = F.relu(self.text_fc(text))\n",
    "        audio = F.relu(self.audio_fc(audio))\n",
    "        \n",
    "        # LSTM for temporal processing\n",
    "        output_v, (vision_h, _) = self.vision_lstm(vision)\n",
    "        output_t, (text_h, _) = self.text_lstm(text)\n",
    "        output_a, (audio_h, _) = self.audio_lstm(audio)\n",
    "\n",
    "        # 对单模态的LSTM输出进行直接相加得到feature\n",
    "        # TODO: feature\n",
    "        _, (fusion_tensor, _) = self.mm_lstm(feature)\n",
    "\n",
    "        # Concatenate the final hidden states\n",
    "        output = self.fc(fusion_tensor[-1])\n",
    "        \n",
    "        # Apply sigmoid to constrain output to (0, 1)\n",
    "        # TODO\n",
    "        # Scale and shift to range (-3, 3)\n",
    "        # TODO\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8554f28a-331c-424b-a15f-856484527278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_mosi_regression(y_pred, y_true, exclude_zero=False):\n",
    "    test_preds = y_pred.view(-1).cpu().detach().numpy()\n",
    "    test_truth = y_true.view(-1).cpu().detach().numpy()\n",
    "\n",
    "    test_preds_a7 = np.clip(test_preds, a_min=-3., a_max=3.)\n",
    "    test_truth_a7 = np.clip(test_truth, a_min=-3., a_max=3.)\n",
    "    test_preds_a5 = np.clip(test_preds, a_min=-2., a_max=2.)\n",
    "    test_truth_a5 = np.clip(test_truth, a_min=-2., a_max=2.)\n",
    "\n",
    "    mae = np.mean(np.absolute(test_preds - test_truth))\n",
    "    corr = np.corrcoef(test_preds, test_truth)[0][1]\n",
    "    mult_a7 = multiclass_acc(test_preds_a7, test_truth_a7)\n",
    "    mult_a5 = multiclass_acc(test_preds_a5, test_truth_a5)\n",
    "    \n",
    "    non_zeros = np.array([i for i, e in enumerate(test_truth) if e != 0])\n",
    "    non_zeros_binary_truth = (test_truth[non_zeros] > 0)\n",
    "    non_zeros_binary_preds = (test_preds[non_zeros] > 0)\n",
    "\n",
    "    non_zeros_acc2 = accuracy_score(non_zeros_binary_preds, non_zeros_binary_truth)\n",
    "    non_zeros_f1_score = f1_score(non_zeros_binary_preds, non_zeros_binary_truth, average='weighted')\n",
    "    \n",
    "    eval_results = {\n",
    "        \"Non0_acc_2\":  round(non_zeros_acc2, 4),\n",
    "        \"Non0_F1_score\": round(non_zeros_f1_score, 4),\n",
    "        \"Mult_acc_5\": round(mult_a5, 4),\n",
    "        \"Mult_acc_7\": round(mult_a7, 4),\n",
    "        \"MAE\": round(mae, 4),\n",
    "        \"Corr\": round(corr, 4)\n",
    "    }\n",
    "    return eval_results\n",
    "\n",
    "def multiclass_acc(y_pred, y_true):\n",
    "    y_pred = np.round(y_pred)\n",
    "    y_true = np.round(y_true)\n",
    "\n",
    "    # Compute the accuracy\n",
    "    # TODO: 注意，这里统计的是总的分类准确率，而不是在每个类别上的准确率。\n",
    "    \n",
    "    return acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20bce85d-d302-4029-abe3-74c3fdaeee69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, valid_loader, criterion, optimizer, scheduler, device, epochs):\n",
    "    model.to(device)\n",
    "\n",
    "    best_corr = 0.\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, (vision, text, audio, labels) in enumerate(train_loader):\n",
    "            vision, text, audio, labels = vision.to(device), text.to(device), audio.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 模型前向获得输出：\n",
    "            # TODO\n",
    "            # 计算损失：\n",
    "            # TODO\n",
    "            # 反向传播，计算梯度\n",
    "            # TODO\n",
    "            \n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "        val_corr = validate_model(model, valid_loader, criterion, device)\n",
    "\n",
    "        if val_corr > best_corr:\n",
    "            best_corr = val_corr\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), 'best_model.pth')\n",
    "\n",
    "    print(f\"Best model saved with val_corr {best_corr} at epoch {best_epoch}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0cbfa4-2c90-4d6a-bc5c-76285e8ef036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_loader, criterion, device):\n",
    "    model.eval()\n",
    "    valid_loss = 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for vision, text, audio, labels in valid_loader:\n",
    "            vision, text, audio, labels = vision.to(device), text.to(device), audio.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(vision, text, audio)\n",
    "            loss = criterion(outputs.squeeze(), labels.squeeze())\n",
    "\n",
    "            valid_loss += loss.item()\n",
    "\n",
    "            all_preds.append(outputs)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "    print(f'Validation Loss: {valid_loss/len(valid_loader):.4f}')\n",
    "    \n",
    "    all_preds = torch.cat(all_preds, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "\n",
    "    # 计算评价指标\n",
    "    # TODO\n",
    "    print(eval_results)\n",
    "\n",
    "    return eval_results[\"Corr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52dfb72b-e874-45b8-b745-191147d63b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    # 固定随机数种子，确保实验结果可重复性\n",
    "    seed = 42\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    print(device)\n",
    "    \n",
    "    # 定义损失函数criterion, 使用均方误差损失。可以使用pytorch封装好的函数，也可以根据公式手写：\n",
    "    # TODO\n",
    "    \n",
    "    learning_rate = 1e-3\n",
    "    epochs = 20\n",
    "    \n",
    "    # Initialize the model.\n",
    "    # TODO\n",
    "\n",
    "    \n",
    "    data_path = './mosi_raw.pkl'\n",
    "    # 初始化训练集和验证集的数据集类\n",
    "    # TODO: train_dataset\n",
    "    # TODO: valid_dataset\n",
    "    # 初始化训练集和验证集的加载器，要求batch_size=16\n",
    "    # TODO: train_loader，参数shuffle=True\n",
    "    # TODO: valid_loader，参数shuffle=False\n",
    "\n",
    "    # Initialize the optimizer and scheduler.\n",
    "    # TODO: 使用Adam优化器\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=epochs*len(train_loader))\n",
    "\n",
    "    # 调用训练函数，注意传入对应参数：\n",
    "    # TODO\n",
    "\n",
    "    # 加载最佳epoch参数\n",
    "    best_model_state = torch.load('best_model.pth')\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # 初始化测试集的数据集类和加载器\n",
    "    # TODO: test_dataset\n",
    "    # TODO: test_loader\n",
    "    \n",
    "    print(\"\\n========== test results: ==========\\n\")\n",
    "    validate_model(model, test_loader, criterion, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ad2721-c1c0-406f-9958-ccd17805f9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
