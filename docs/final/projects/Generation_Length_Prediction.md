# decode长度预测

# 课程大作业：基于Llama-3.2-1B-Instruct的LLM输出长度预测
---

## 一、任务说明

### 1.1 背景要求

基于 Transformer 的大语言模型（LLM）在推理过程中具有自回归的特性，即生成过程是逐词（token-by-token）进行的。在每一步生成中，模型根据先前生成的 token 来预测下一个 token，直到生成结束标志（如 <EOS> 或达到最大长度限制）。这种方式带来了一个关键问题——生成长度的不确定性。这意味着无法提前预知计算和存储需求。在本次实验中，我们将探讨如何通过提示词（prompt）来预测生成的长度 / 预测请求在一定时间内是否会结束。

- **方法一（独立模型）**：使用BERT构建分类器，仅通过输入文本预测输出长度区间
- **方法二（架构修改）**：修改Llama-3.2-1B-Instruct模型结构实现端到端预测，不使用任何外部的辅助模型进行预测

### 1.2 数据集说明

| 数据集类型 | 内容描述                              | 备注                          |
|------------|---------------------------------------|-------------------------------|
| 提供的数据集     | `dataset.csv` | 在附件中的文件。包含prompt和使用Llama-3.2-1B-Instruct进行5次实验的输出长度均值      |
| 评分数据集     | `judge.csv`                      | **需要提交**的文件。仅包含prompt。            |

---

## 二、方法设计规范

### 2.1 BERT分类方案（方法一）

#### 核心要求

1. **特征编码**：

    ```python
    # 使用CLS向量作为语义表征
    inputs = tokenizer(text, return_tensors='pt', padding='max_length', max_length=512)
    outputs = model(**inputs)
    cls_embedding = outputs.last_hidden_state[:,0,:]  # [batch_size, 768]
    ```

2. **长度分桶策略**：

    - 类别0: ([0, 200)) tokens
    - 类别1: ([200, 400)) tokens
    - 类别2: ([400, 600)) tokens
    - 类别3: ([600, 800)) tokens
    - 类别4: (≥800) tokens

3. **模型约束**：

    - 在该实验中，你不需要实际使用LLM进行推理，该实验的预测过程与LLM生成过程完全解耦。

### 2.2 LLM结构修改（方法二）

#### 架构修改

1. **模型架构设计**。
    
        - 在Llama-3.2-1B-Instruct的基础上，修改模型结构实现输出长度预测。需要考虑模型设计。

2. **训练策略**。
    
        - 需要考虑优化长度预测任务。

3. **防干扰机制**。

    - 不使用任何外部的辅助模型进行预测，且不会影响实际输出内容质量和长度。

---

## 三、实验实施要求

### 3.1 数据预处理

- 统一使用Llama-3的SentencePiece分词器处理


### 3.2 评估指标

本实验不限制具体的评估指标。你需要确保评估指标能够合适地衡量长度预测的准确性，例如：如果采用分类任务，可能采用分类任务的常用评估指标。你还可以将其视为其他合适任务。

### 3.3 必做实验

- **基线对比**：对比提示词方法（"请先预测回答长度"）的预测误差
- **消融实验**：验证联合训练策略的有效性（关闭MSE_Loss）

---

## 四、提交要求

### 4.1 提交内容

1. **代码包**：

    ```bash
    ├── bert_predict/       # 方法一实现
    │   ├── preprocess.py
    │   └── train.py
    ├── llama_modify/       # 方法二实现
    │   ├── modeling_llama.py
    │   └── finetune.py
    ├── judge.csv           # 预测数据集，用于评分
    └── requirements.txt

    ```

2. **实验结果**：

    - 测试集预测结果CSV文件（含ID、预测长度、真实长度三列）
    - 各实验的评估指标对比表格（Markdown格式）

### 4.2 评分标准

| 评分维度       | 细则说明                                      | 占比 |
|----------------|-----------------------------------------------|------|
| 方法创新性     | BERT特征工程/LLM修改设计的合理性              | 25%  |
| 结果准确性     | 测试集MAE ≤ 100 tokens            | 40%  |
| 代码质量       | PEP8规范、模块化设计、注释完整性              | 20%  |
| 报告质量       | 实验分析深度、可视化呈现效果                  | 15%  |

---

## 五、注意事项

1. **硬件限制**：

    - 方法一允许在CPU环境运行
    - 方法二需提供简要的GPU内存占用分析（使用nvidia-smi记录）

2. **实验要求**：

    - 不要通过任何方式干预和引导模型的生成长度，包括但不限于：预设prompt引导生成长度、截断模型生成等。
    - 需提交训练过程的loss曲线截图

3. **参考文献**：

    - 如果你在实验和报告中参考了已发表的文献，请列出你所参考的相关文献。

4. **截止日期**：2025年6月10日 23:59（UTC+8）

5. 如有疑问，请联系 wzbwangzhibin@gmail.com 或 spli161006@gmail.com。
