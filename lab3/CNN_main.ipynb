{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6376419e",
   "metadata": {},
   "source": [
    "# 实验任务二：使用CNN来进行图像分类\n",
    "## CIFAR-10 数据集\n",
    "本次实验使用CIFAR-10 数据集来进行实验。\n",
    "CIFAR-10 数据集包含 60,000 张 32×32 像素的彩色图像，\n",
    "分为 10 个类别，每个类别有 6,000 张图像。\n",
    "具体类别包括飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。\n",
    "数据集被分为训练集和测试集，\n",
    "其中训练集包含 50,000 张图像，测试集包含 10,000 张图像。\n",
    "## 1. 在CIFAR数据集上实现CNN\n",
    "本次任务要求补全代码中空缺部分，包括实现一个CNN类，以及训练过程代码\n",
    "\n",
    "数据集下载链接：\n",
    "\n",
    "https://box.nju.edu.cn/f/d59d5d910d754c3091f5/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7434d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81602cb6",
   "metadata": {},
   "source": [
    "导入CIFAR-10数据集："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd51464",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# 下载并加载训练集\n",
    "trainset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# 创建数据加载器\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,\n",
    "    batch_size=32,\n",
    "    shuffle=True\n",
    ")\n",
    "testset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=32,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c307b5",
   "metadata": {},
   "source": [
    "定义CNN网络："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c80fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        #TODO: 实现模型结构\n",
    "        #TODO 实现self.conv1:卷积层\n",
    "        #TODO 实现self.conv2:卷积层\n",
    "        #TODO 实现self.pool: MaxPool2d\n",
    "        #TODO 实现self.fc1: 线性层\n",
    "        #TODO 实现self.fc2：线性层\n",
    "        #TODO 实现 self.dropout: Dropout层\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555e410",
   "metadata": {},
   "source": [
    "进行训练："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47923b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, device):\n",
    "    num_epochs = 15\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            #TODO:实现训练部分，完成反向传播过程\n",
    "            #TODO: optimizer梯度清除\n",
    "            #TODO: 模型输入\n",
    "            #TODO: 计算损失\n",
    "            #TODO: 反向传播\n",
    "            #TODO: 更新参数\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:  # 每100个batch打印一次损失\n",
    "                print(\n",
    "                    f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        # 每个epoch结束后在测试集上评估模型\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f'Test Accuracy: {100 * correct / total:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e70fb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#创建模型\n",
    "model = SimpleCNN().to(device)\n",
    "train(model, trainloader, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8d7195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def denormalize(tensor):\n",
    "    # 输入是归一化后的张量 [C, H, W]\n",
    "    # 反归一化：(tensor * std) + mean\n",
    "    # 原始归一化参数：mean=0.5, std=0.5\n",
    "    return tensor * 0.5 + 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6983f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iter = iter(trainloader)\n",
    "images, labels = next(data_iter)  # 获取第一个batch\n",
    "\n",
    "# 反归一化并转换为numpy\n",
    "img = denormalize(images[0]).numpy()  # 取batch中的第一张\n",
    "img = np.transpose(img, (1, 2, 0))    # 从(C, H, W)转为(H, W, C)\n",
    "\n",
    "# 显示图像\n",
    "plt.imshow(img)\n",
    "plt.title(f\"Label: {trainset.classes[labels[0]]}\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c654c8e",
   "metadata": {},
   "source": [
    "## 2. 在MNIST数据集上实现CNN：\n",
    "在实验二中我们实现了在MNIST数据集上进行分类，使用本节的CNN又该如何实现，结合本节内容以及实验二内容尝试实现"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb397a",
   "metadata": {},
   "source": [
    "## 3. 卷积神经网络（LeNet）\n",
    "本节将介绍LeNet，它是最早发布的卷积神经网络之一，\n",
    "因其在计算机视觉任务中的高效性能而受到广泛关注。 \n",
    "这个模型是由AT&T贝尔实验室的研究员Yann LeCun在1989年提出的（并以其命名），\n",
    "目的是识别图像 (LeCun et al., 1998)中的手写数字。 \n",
    "当时，Yann LeCun发表了第一篇通过反向传播成功训练卷积神经网络的研究，\n",
    "这项工作代表了十多年来神经网络研究开发的成果。\n",
    "\n",
    "我们对原始模型做了一点小改动，去掉了最后一层的高斯激活。除此之外，这个网络与最初的LeNet-5一致。\n",
    "\n",
    "以下是通过实例化一个Sequential来实现LeNet代码."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5f37e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5, padding=2), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45f0139",
   "metadata": {},
   "source": [
    "下面，我们将一个大小为28x28 的单通道（黑白）图像通过LeNet。\n",
    "通过在每一层打印输出的形状，我们可以检查模型，以确保其操作与我们期望的图中一致"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ff87f78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d output shape: \t torch.Size([1, 6, 28, 28])\n",
      "Sigmoid output shape: \t torch.Size([1, 6, 28, 28])\n",
      "AvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\n",
      "Conv2d output shape: \t torch.Size([1, 16, 10, 10])\n",
      "Sigmoid output shape: \t torch.Size([1, 16, 10, 10])\n",
      "AvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\n",
      "Flatten output shape: \t torch.Size([1, 400])\n",
      "Linear output shape: \t torch.Size([1, 120])\n",
      "Sigmoid output shape: \t torch.Size([1, 120])\n",
      "Linear output shape: \t torch.Size([1, 84])\n",
      "Sigmoid output shape: \t torch.Size([1, 84])\n",
      "Linear output shape: \t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.rand(size=(1, 1, 28, 28), dtype=torch.float32)\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape: \\t',X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8a1579",
   "metadata": {},
   "source": [
    "结合图片中所给出的LeNet以及给出的nn.Sequential，将前文给出的net结构以类的方式实现，并实现在\n",
    "MNIST数据集上的分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dca7988",
   "metadata": {},
   "source": [
    "## 4. 批量规范化\n",
    "训练深层神经网络是十分困难的，特别是在较短的时间内使他们收敛更加棘手。 \n",
    "本节将介绍批量规范化（batch normalization） (Ioffe and Szegedy, 2015)，\n",
    "这是一种流行且有效的技术，可持续加速深层网络的收敛速度。\n",
    "\n",
    "为什么需要批量规范化层呢？让我们来回顾一下训练神经网络时出现的一些实际挑战。\n",
    "\n",
    "首先，数据预处理的方式通常会对最终结果产生巨大影响。  \n",
    "使用真实数据时，我们的第一步是标准化输入特征，使其平均值为0，方差为1。 \n",
    "直观地说，这种标准化可以很好地与我们的优化器配合使用，因为它可以将参数的量级进行统一。\n",
    "\n",
    "第二，对于典型的多层感知机或卷积神经网络。当我们训练时，中间层中的变量（\n",
    "例如，多层感知机中的仿射变换输出）\n",
    "可能具有更广的变化范围：不论是沿着从输入到输出的层，跨同一层中的单元，\n",
    "或是随着时间的推移，模型参数的随着训练更新变幻莫测。 批量规范化的发明者非正式地假设，\n",
    "这些变量分布中的这种偏移可能会阻碍网络的收敛。 \n",
    "直观地说，我们可能会猜想，如果一个层的可变值是另一层的100倍，这可能需要对学习率进行补偿调整。\n",
    "\n",
    "第三，更深层的网络很复杂，容易过拟合。 这意味着正则化变得更加重要。\n",
    "\n",
    "批量规范化应用于单个可选层（也可以应用到所有层），其原理如下：在每次训练迭代中，\n",
    "我们首先规范化输入，即通过减去其均值并除以其标准差，其中两者均基于当前小批量处理。 \n",
    "接下来，我们应用比例系数和比例偏移。 正是由于这个基于批量统计的标准化，才有了批量规范化的名称。\n",
    "\n",
    "请注意，如果我们尝试使用大小为1的小批量应用批量规范化，我们将无法学到任何东西。 \n",
    "这是因为在减去均值之后，每个隐藏单元将为0。 所以，\n",
    "只有使用足够大的小批量，批量规范化这种方法才是有效且稳定的。 \n",
    "请注意，在应用批量规范化时，批量大小的选择可能比没有批量规范化时更重要。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044eb612",
   "metadata": {},
   "source": [
    "### 从零实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ec392a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l\n",
    "\n",
    "\n",
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # 通过is_grad_enabled来判断当前模式是训练模式还是预测模式\n",
    "    if not torch.is_grad_enabled():\n",
    "        # 如果是在预测模式下，直接使用传入的移动平均所得的均值和方差\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # 使用全连接层的情况，计算特征维上的均值和方差\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # 使用二维卷积层的情况，计算通道维上（axis=1）的均值和方差。\n",
    "            # 这里我们需要保持X的形状以便后面可以做广播运算\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # 训练模式下，用当前的均值和方差做标准化\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum * moving_mean + (1.0 - momentum) * mean\n",
    "        moving_var = momentum * moving_var + (1.0 - momentum) * var\n",
    "    Y = gamma * X_hat + beta  # 缩放和移位\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c3d0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features：完全连接层的输出数量或卷积层的输出通道数。\n",
    "    # num_dims：2表示完全连接层，4表示卷积层\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # 参与求梯度和迭代的拉伸和偏移参数，分别初始化成1和0\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # 非模型参数的变量初始化为0和1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # 如果X不在内存上，将moving_mean和moving_var\n",
    "        # 复制到X所在显存上\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # 保存更新过的moving_mean和moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.9)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa66622",
   "metadata": {},
   "source": [
    "为了更好理解如何应用BatchNorm，下面我们将其应用于LeNet模型 \n",
    "回想一下，批量规范化是在卷积层或全连接层之后、相应的激活函数之前应用的."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84103ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), BatchNorm(6, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), BatchNorm(16, num_dims=4), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(16*4*4, 120), BatchNorm(120, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), BatchNorm(84, num_dims=2), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105de7bf",
   "metadata": {},
   "source": [
    "### 简单实现\n",
    "除了使用我们刚刚定义的BatchNorm，我们也可以直接使用深度学习框架中定义的BatchNorm。\n",
    "该代码看起来几乎与我们上面的代码相同。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e091503",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1, 6, kernel_size=5), nn.BatchNorm2d(6), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(6, 16, kernel_size=5), nn.BatchNorm2d(16), nn.Sigmoid(),\n",
    "    nn.AvgPool2d(kernel_size=2, stride=2), nn.Flatten(),\n",
    "    nn.Linear(256, 120), nn.BatchNorm1d(120), nn.Sigmoid(),\n",
    "    nn.Linear(120, 84), nn.BatchNorm1d(84), nn.Sigmoid(),\n",
    "    nn.Linear(84, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2b1eb3",
   "metadata": {},
   "source": [
    "练习：使用上述定义的包含BatchNorm的LeNet网络，\n",
    "实现在MNIST数据集上的图像分类(直接使用nn.Sequential或者自定义类均可)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beaa3f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
